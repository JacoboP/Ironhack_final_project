{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones importadas\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier       \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de lectura de csv para añadir la funcionalidad de que ponga la columna nombre como index\n",
    "\n",
    "def read_file(file):\n",
    "    file = pd.read_csv(file)\n",
    "    file.set_index(('Name'), inplace=True)\n",
    "    return file\n",
    "\n",
    "top5_college = read_file('../input/model_dummies_college_nba.csv')\n",
    "draft19_class = read_file('../input/model_draft19_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy: \n",
      " 0.8608695652173913\n",
      "confusion matrix: \n",
      " [[99  0]\n",
      " [16  0]]\n",
      "---------------------\n",
      "LogisticRegression\n",
      "Accuracy: \n",
      " 0.8608695652173913\n",
      "confusion matrix: \n",
      " [[99  0]\n",
      " [16  0]]\n",
      "---------------------\n",
      "KNeighborsClassifier\n",
      "Accuracy: \n",
      " 0.8347826086956521\n",
      "confusion matrix: \n",
      " [[96  3]\n",
      " [16  0]]\n",
      "---------------------\n",
      "KNeighborsClassifier\n",
      "Accuracy: \n",
      " 0.8521739130434782\n",
      "confusion matrix: \n",
      " [[98  1]\n",
      " [16  0]]\n",
      "---------------------\n",
      "RandomForestClassifier\n",
      "Accuracy: \n",
      " 0.8608695652173913\n",
      "confusion matrix: \n",
      " [[99  0]\n",
      " [16  0]]\n",
      "---------------------\n",
      "GaussianNB\n",
      "Accuracy: \n",
      " 0.7739130434782608\n",
      "confusion matrix: \n",
      " [[85 14]\n",
      " [12  4]]\n",
      "---------------------\n",
      "SVC\n",
      "Accuracy: \n",
      " 0.8608695652173913\n",
      "confusion matrix: \n",
      " [[99  0]\n",
      " [16  0]]\n",
      "---------------------\n",
      "GradientBoostingClassifier\n",
      "Accuracy: \n",
      " 0.8521739130434782\n",
      "confusion matrix: \n",
      " [[97  2]\n",
      " [15  1]]\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# Función para aplicar modelos de machine learning y determinar su accuracy y su confusion matrix.\n",
    "\n",
    "def modelos(data,columnadep):\n",
    "    \n",
    "    X=data.loc[:,data.columns!= columnadep]\n",
    "    y=data[columnadep]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Definición de modelos                                          # Modelos aplicados: \n",
    "    \n",
    "    cls = svm.SVC(gamma='auto', probability=True)                    # 1. Linear regresion\n",
    "    lr = LogisticRegression(solver ='liblinear',max_iter=500)        # 2. Logistic regresion\n",
    "    neigh3 = KNeighborsClassifier(n_neighbors=3)                     # 3. k-Neighbours k=3 \n",
    "    neigh5 = KNeighborsClassifier(n_neighbors=5)                     # 4. k-Neighbours k=5 \n",
    "    rf=RandomForestClassifier(n_estimators=500, criterion='gini')    # 5. RandomForest \n",
    "    gnb = GaussianNB()                                               # 6. Gaussian Method\n",
    "    svc = SVC(kernel='rbf', gamma='scale')                           # 7. SVC\n",
    "    gbc=GradientBoostingClassifier()                                 # 8. GradientBoostingClassifier\n",
    "    \n",
    "    # Lista de modelos que usamos\n",
    "    \n",
    "    modelos=[cls, lr, neigh3, neigh5, rf, gnb, svc, gbc]\n",
    "    \n",
    "    # Bucle para aplicación de modelos\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_predict = modelo.predict(X_test)\n",
    "        print('{}'.format(modelo.__class__.__name__))\n",
    "        print('Accuracy:',\"\\n\", metrics.accuracy_score(y_test, y_predict))\n",
    "        print(\"confusion matrix:\",\"\\n\",confusion_matrix(y_test, y_predict))\n",
    "        print('---------------------')\n",
    "\n",
    "modelos(top5_college, 'TOP-5_Top5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de over sampling  - creación de valores sinteticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para valancear el modelo creamos valores sinteticos por medio de over sampling\n",
    "\n",
    "def oversampling(data,columnadep):\n",
    "    \n",
    "    # Definimos cual será X e y en el modelo\n",
    "    \n",
    "    X = data\n",
    "    y = data[columnadep]\n",
    "\n",
    "    X_resample, y_resample = SVMSMOTE().fit_resample(X, y)\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_resample,\n",
    "                                                                y_resample,\n",
    "                                                                test_size = 0.20, \n",
    "                                                                random_state = 10)\n",
    "\n",
    "    # Definimos el modelo con el que generamos valores sinteticos\n",
    "    \n",
    "    rf=RandomForestClassifier(n_estimators=500, criterion='gini')\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # Generamos con RandomForest los valores sinteticos\n",
    "\n",
    "    y_pred_over = rf.predict(X_test_r)\n",
    "\n",
    "    # Creamos un DataFrame con los valores y le ponemos los mismas columnas que nuestro anterior DataFrame\n",
    "    \n",
    "    over_samplingDF = pd.DataFrame(X_test_r)\n",
    "    \n",
    "    colheaders = data.columns   \n",
    "    dictiona = {x: y for x, y in zip(range(18), colheaders)}\n",
    "    over_samplingDF = over_samplingDF.rename(index = str, columns=dictiona)\n",
    "    \n",
    "    # Print para ver el DataFrame resultante\n",
    "    \n",
    "#    print('Modelo:')\n",
    "#    display(over_samplingDF.head())\n",
    "#    print('Shape del modelo:')\n",
    "#    display(over_samplingDF.shape)\n",
    "    \n",
    "    return over_samplingDF\n",
    "\n",
    "over_samplingDF = oversampling(top5_college, 'TOP-5_Top5')\n",
    "print(over_samplingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un gridsearch para obtener los parámetros óptimos para el modelo de RandomForest\n",
    "\n",
    "def gridsearch(data, columnadep):\n",
    "\n",
    "    X = data.loc[:,over_samplingDF.columns!= columnadep]\n",
    "    y = data[columnadep]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    rfc = RandomForestClassifier(random_state=42)                                 # Modelo seleccionado\n",
    "    \n",
    "    param_grid = {                                                              # Parámetros del gridsearch\n",
    "       'n_estimators': [200, 500],\n",
    "       'max_features': ['auto', 'sqrt'],\n",
    "       'max_depth' : [7,8],\n",
    "       'criterion' :['gini', 'entropy']}\n",
    "\n",
    "    fitting = rfc.fit(X_test,y_test)\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    CV_rfc.fit(X_train, y_train)\n",
    "    CV_rfc.best_params_\n",
    "    return CV_rfc.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch aplicado a RF de over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con los parámetros obtenidos en el Gridsearch entrenamos el modelo\n",
    "\n",
    "def gridsearch_model(data, columnadep):\n",
    "    \n",
    "    X=data.loc[:,over_samplingDF.columns!= columnadep]\n",
    "    y=data[columnadep]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    rf=RandomForestClassifier(criterion=gridsearch['criterion'], max_depth=gridsearch['max_depth'], \n",
    "                              max_features=gridsearch['max_features'], n_estimators=gridsearch['n_estimators'])\n",
    "    rf.fit(X_train, y_train) \n",
    "\n",
    "    y_pred_rf= rf.predict(X_test)\n",
    "\n",
    "#    print(\"Accuracy rf:\",metrics.accuracy_score(y_test, y_pred_rf))\n",
    "#    print(\"Confusion matrix rf\",\"\\n\",confusion_matrix(y_test, y_pred_rf))\n",
    "    \n",
    "    return y_pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación del modelo al draft de 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para determinar los 5 jugadores que el modelo selecciona como más probables en el draft de 2019 creamos un bucle que repita el entrenamiento anterior 1000 veces\n",
    "# Ponemos un contador que expresa en valor 1 si ese jugador sería seleccionable entre los 5 primeros del draft 2019\n",
    "\n",
    "def aplicacion_final(data, columnadep, datadraft):\n",
    "\n",
    "    counter=0\n",
    "    \n",
    "    for i in range(100):\n",
    "        \n",
    "        # Modelo RandomForest generado\n",
    "        \n",
    "        X=data.loc[:,data.columns!= columnadep]\n",
    "        y=data[columnadep]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        rf=RandomForestClassifier(criterion=gridsearch['criterion'], max_depth=gridsearch['max_depth'], \n",
    "                              max_features=gridsearch['max_features'], n_estimators=gridsearch['n_estimators'])\n",
    "        \n",
    "        rf.fit(X_train, y_train) \n",
    "        y_pred_rf= rf.predict(X_test)\n",
    "\n",
    "        # Modelo RandomForest aplicado para predecir el draft\n",
    "        \n",
    "        counter += rf.predict(draft19_class)\n",
    "        \n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con los valores obtenidos en el paso anterior creamos una columna, ordenamos esta según la columna Prediction y extraemos los 5 primeros valores\n",
    "\n",
    "def final(counter):\n",
    "\n",
    "    draft19_class['Prediction'] = counter\n",
    "\n",
    "    prediction = draft19_class.sort_values(by=['Prediction'], ascending=False)\n",
    "    \n",
    "    return prediction.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_college = read_file('../input/model_dummies_college_nba.csv')\n",
    "draft19_class = read_file('../input/model_draft19_class.csv')\n",
    "over_samplingDF = oversampling(top5_college, 'TOP-5_Top5')\n",
    "gridsearch = gridsearch(over_samplingDF, 'TOP-5_Top5')\n",
    "gridsearch2 = gridsearch_model(over_samplingDF, 'TOP-5_Top5')\n",
    "counter = aplicacion_final(over_samplingDF, 'TOP-5_Top5', draft19_class)\n",
    "final(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
